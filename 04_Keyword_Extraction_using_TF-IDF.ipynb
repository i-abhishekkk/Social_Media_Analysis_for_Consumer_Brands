{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb7240e",
   "metadata": {},
   "source": [
    "## 4 -- KEYWORD EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dcfcf8",
   "metadata": {},
   "source": [
    "Keyword extraction is a methodology to automatically detect important words that can be used to represent the text and can be used for topic modeling. This is a very efficient way to get insights from a huge amount of unstructured text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7e523",
   "metadata": {},
   "source": [
    "### 4.1 -- Installing and Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6866c3e",
   "metadata": {},
   "source": [
    "Scikit-learn is a free machine learning library for Python. It features various algorithms like support vector machine, random forests, and k-neighbours, and it also supports Python numerical and scientific libraries like NumPy and SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d485e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (1.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424d7dd",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP). It contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12af1082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maiab\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee803b",
   "metadata": {},
   "source": [
    "Importing warnings and sklearn.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716ab940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be89387",
   "metadata": {},
   "source": [
    "Importing some basic libraries which we are going to need for further process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6fe30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5c3a7",
   "metadata": {},
   "source": [
    "### 4.2 -- Reading csv file to perform Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cedde1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas .read method to read our csv file..\n",
    "df_5 = pd.read_csv('03_Sentiment_Analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bdb41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>PRODUCT_NAME</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PRODUCT_CATEGORY</th>\n",
       "      <th>PACK_SIZE</th>\n",
       "      <th>REVIEW_COUNT</th>\n",
       "      <th>REVIEW_DATE</th>\n",
       "      <th>REVIEW_TIME</th>\n",
       "      <th>PRICE_RATING</th>\n",
       "      <th>QUALITY_RATING</th>\n",
       "      <th>VALUE_RATING</th>\n",
       "      <th>REVIEW_CONTENT</th>\n",
       "      <th>URL</th>\n",
       "      <th>DATE_OF_CREATION</th>\n",
       "      <th>LAST_UPDATED_DATE</th>\n",
       "      <th>STATES</th>\n",
       "      <th>SENTIMENT_SCORE</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>REVIEW_PREPROCESSED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8904417301762</td>\n",
       "      <td>Vitamin C Daily Glow Face Cream With Vitamin C...</td>\n",
       "      <td>249.00</td>\n",
       "      <td>skin</td>\n",
       "      <td>80g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>16:38:37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mamaearth always wins my heart with new surpri...</td>\n",
       "      <td>https://mamaearth.in/product/vitamin-c-daily-g...</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-04</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>mamaearth always win heart new surprise called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8904417300338</td>\n",
       "      <td>Green Tea Face Wash With Green Tea &amp; Collagen ...</td>\n",
       "      <td>399.00</td>\n",
       "      <td>skin</td>\n",
       "      <td>100ml</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>16:34:36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I've had acne my entire life, and this appears...</td>\n",
       "      <td>https://mamaearth.in/product/green-tea-face-wa...</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>ive acne entire life appears face wash doesnt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8904417300338</td>\n",
       "      <td>Green Tea Face Wash With Green Tea &amp; Collagen ...</td>\n",
       "      <td>399.00</td>\n",
       "      <td>skin</td>\n",
       "      <td>100ml</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>16:34:26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Great cleanser, gentle and makes my face fresh...</td>\n",
       "      <td>https://mamaearth.in/product/green-tea-face-wa...</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>great cleanser gentle make face fresh clean us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8904417300338</td>\n",
       "      <td>Green Tea Face Wash With Green Tea &amp; Collagen ...</td>\n",
       "      <td>399.00</td>\n",
       "      <td>skin</td>\n",
       "      <td>100ml</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>16:34:15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I use Mamaearth green tea range and the result...</td>\n",
       "      <td>https://mamaearth.in/product/green-tea-face-wa...</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>Goa</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>use mamaearth green tea range result shocked p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8904417300338</td>\n",
       "      <td>Green Tea Face Wash With Green Tea &amp; Collagen ...</td>\n",
       "      <td>399.00</td>\n",
       "      <td>skin</td>\n",
       "      <td>100ml</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>16:34:01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I have sensitive skin, and I did not experienc...</td>\n",
       "      <td>https://mamaearth.in/product/green-tea-face-wa...</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>sensitive skin experience breakout using produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SKU                                       PRODUCT_NAME   PRICE  \\\n",
       "0  8904417301762  Vitamin C Daily Glow Face Cream With Vitamin C...  249.00   \n",
       "1  8904417300338  Green Tea Face Wash With Green Tea & Collagen ...  399.00   \n",
       "2  8904417300338  Green Tea Face Wash With Green Tea & Collagen ...  399.00   \n",
       "3  8904417300338  Green Tea Face Wash With Green Tea & Collagen ...  399.00   \n",
       "4  8904417300338  Green Tea Face Wash With Green Tea & Collagen ...  399.00   \n",
       "\n",
       "  PRODUCT_CATEGORY PACK_SIZE  REVIEW_COUNT REVIEW_DATE REVIEW_TIME  \\\n",
       "0             skin       80g           1.0  2022-08-29    16:38:37   \n",
       "1             skin     100ml          47.0  2022-09-02    16:34:36   \n",
       "2             skin     100ml          47.0  2022-09-02    16:34:26   \n",
       "3             skin     100ml          47.0  2022-09-02    16:34:15   \n",
       "4             skin     100ml          47.0  2022-09-02    16:34:01   \n",
       "\n",
       "   PRICE_RATING  QUALITY_RATING  VALUE_RATING  \\\n",
       "0           5.0             0.0           0.0   \n",
       "1           5.0             0.0           0.0   \n",
       "2           5.0             0.0           0.0   \n",
       "3           5.0             0.0           0.0   \n",
       "4           4.0             0.0           0.0   \n",
       "\n",
       "                                      REVIEW_CONTENT  \\\n",
       "0  Mamaearth always wins my heart with new surpri...   \n",
       "1  I've had acne my entire life, and this appears...   \n",
       "2  Great cleanser, gentle and makes my face fresh...   \n",
       "3  I use Mamaearth green tea range and the result...   \n",
       "4  I have sensitive skin, and I did not experienc...   \n",
       "\n",
       "                                                 URL DATE_OF_CREATION  \\\n",
       "0  https://mamaearth.in/product/vitamin-c-daily-g...       2022-08-17   \n",
       "1  https://mamaearth.in/product/green-tea-face-wa...       2022-08-17   \n",
       "2  https://mamaearth.in/product/green-tea-face-wa...       2022-08-17   \n",
       "3  https://mamaearth.in/product/green-tea-face-wa...       2022-08-17   \n",
       "4  https://mamaearth.in/product/green-tea-face-wa...       2022-08-17   \n",
       "\n",
       "  LAST_UPDATED_DATE          STATES  SENTIMENT_SCORE SENTIMENT  \\\n",
       "0        2022-09-04       Rajasthan                5  Positive   \n",
       "1        2022-09-01  Madhya Pradesh                5  Positive   \n",
       "2        2022-09-01       Karnataka                5  Positive   \n",
       "3        2022-09-01             Goa                5  Positive   \n",
       "4        2022-09-01         Haryana                4  Positive   \n",
       "\n",
       "                            REVIEW_PREPROCESSED_TEXT  \n",
       "0  mamaearth always win heart new surprise called...  \n",
       "1  ive acne entire life appears face wash doesnt ...  \n",
       "2  great cleanser gentle make face fresh clean us...  \n",
       "3  use mamaearth green tea range result shocked p...  \n",
       "4  sensitive skin experience breakout using produ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfbff36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28228 entries, 0 to 28227\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   SKU                       28228 non-null  int64  \n",
      " 1   PRODUCT_NAME              28228 non-null  object \n",
      " 2   PRICE                     28228 non-null  object \n",
      " 3   PRODUCT_CATEGORY          28228 non-null  object \n",
      " 4   PACK_SIZE                 28228 non-null  object \n",
      " 5   REVIEW_COUNT              28228 non-null  float64\n",
      " 6   REVIEW_DATE               28228 non-null  object \n",
      " 7   REVIEW_TIME               28228 non-null  object \n",
      " 8   PRICE_RATING              28228 non-null  float64\n",
      " 9   QUALITY_RATING            28228 non-null  float64\n",
      " 10  VALUE_RATING              28228 non-null  float64\n",
      " 11  REVIEW_CONTENT            28228 non-null  object \n",
      " 12  URL                       28228 non-null  object \n",
      " 13  DATE_OF_CREATION          28228 non-null  object \n",
      " 14  LAST_UPDATED_DATE         28228 non-null  object \n",
      " 15  STATES                    28228 non-null  object \n",
      " 16  SENTIMENT_SCORE           28228 non-null  int64  \n",
      " 17  SENTIMENT                 28228 non-null  object \n",
      " 18  REVIEW_PREPROCESSED_TEXT  28192 non-null  object \n",
      "dtypes: float64(4), int64(2), object(13)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9333c827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 28228 entries, 0 to 28227\n",
      "Series name: REVIEW_PREPROCESSED_TEXT\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "28192 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 220.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_5['REVIEW_PREPROCESSED_TEXT'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d9a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is already pre_processed that's why I've commented this out\n",
    "# # Lower casing and removing punctuations\n",
    "# df_5['REVIEW_PREPROCESSED_TEXT'] = df_5['REVIEW_PREPROCESSED_TEXT'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "# df_5.REVIEW_PREPROCESSED_TEXT.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba910ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is already pre_processed that's why I've commented this out\n",
    "# # Removing all the unwanted special characters and numbers by using regex function..\n",
    "# df_5['REVIEW_PREPROCESSED_TEXT'] = df_5['REVIEW_PREPROCESSED_TEXT'].str.replace('[^\\w\\s]', \" \")\n",
    "# df_5.REVIEW_PREPROCESSED_TEXT.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d506605",
   "metadata": {},
   "source": [
    "### 4.3 -- Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed97ddc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Data is already pre_processed that's why I've commented this out\n",
    "# # Lambda function for removing stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "# # stop_words.extend(['karen','pata','usmein','jain','samajh'])\n",
    "# df_5['REVIEW_PREPROCESSED_TEXT'] = df_5['REVIEW_PREPROCESSED_TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
    "# df_5.REVIEW_PREPROCESSED_TEXT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b72d51",
   "metadata": {},
   "source": [
    "### 4.4 -- Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9efc900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling correction consumes large amount of time, that's why I've commented this out\n",
    "\n",
    "# df_5['REVIEW_PREPROCESSED_TEXT'] = df_5['REVIEW_PREPROCESSED_TEXT'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "# df_5.REVIEW_PREPROCESSED_TEXT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cdf78",
   "metadata": {},
   "source": [
    "### 4.5 -- Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c12a57d",
   "metadata": {},
   "source": [
    "Lemmatization is one of the most common text pre-processing techniques used in NLP and machine learning in general. In lemmatization, we try to reduce a given word to its root word. The root word is called a lemma in the lemmatization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564acf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is already pre_processed that's why I've commented this out\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# from textblob import TextBlob\n",
    "# from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96fc18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data is already pre_processed that's why I've commented this out\n",
    "# # Lambda function for lemmatizing each review\n",
    "# df_5['REVIEW_PREPROCESSED_TEXT'] = df_5['REVIEW_PREPROCESSED_TEXT'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "# df_5.REVIEW_PREPROCESSED_TEXT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97e4a8",
   "metadata": {},
   "source": [
    "### 4.6 -- SKLEARN feature_extraction module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f09e3",
   "metadata": {},
   "source": [
    "The sklearn feature_extraction module can be used to extract features in a format supported by machine learning algorithms from datasets consisting of formats such as text and image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1352b2",
   "metadata": {},
   "source": [
    "Importing TfidfVectorizer and CountVectorizer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4b9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11443bd7",
   "metadata": {},
   "source": [
    "### 4.7 -- TfidfVectorizer for unigram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdafd620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maiab\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_unigram = TfidfVectorizer(ngram_range=(1,1))\n",
    "Data_unigram = cv_unigram.fit_transform(df_5.REVIEW_PREPROCESSED_TEXT.values.astype('str'))\n",
    "avg_unigram = Data_unigram.mean(axis=0)\n",
    "avg_unigram = pd.DataFrame(avg_unigram, columns=cv_unigram.get_feature_names())\n",
    "avg_unigram = avg_unigram.T\n",
    "avg_unigram = avg_unigram.rename(columns={0:'SCORE'}) \n",
    "avg_unigram['WORD'] = avg_unigram.index\n",
    "avg_unigram = avg_unigram.sort_values('SCORE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be40449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>0.123058</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.111096</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>0.072872</td>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.055286</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.038185</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usmein</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>usmein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karen</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>karen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pata</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>pata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kah</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>kah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samajh</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>samajh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SCORE     WORD\n",
       "product  0.123058  product\n",
       "good     0.111096     good\n",
       "nice     0.072872     nice\n",
       "like     0.055286     like\n",
       "love     0.038185     love\n",
       "...           ...      ...\n",
       "usmein   0.000003   usmein\n",
       "karen    0.000003    karen\n",
       "pata     0.000003     pata\n",
       "kah      0.000003      kah\n",
       "samajh   0.000003   samajh\n",
       "\n",
       "[12263 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb94fa",
   "metadata": {},
   "source": [
    "### 4.8 -- TfidfVectorizer for trigram range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c29faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maiab\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_trigram = TfidfVectorizer(ngram_range=(3,3))\n",
    "Data_trigram = cv_trigram.fit_transform(df_5.REVIEW_PREPROCESSED_TEXT.values.astype('str'))\n",
    "avg_trigram = Data_trigram.mean(axis=0)\n",
    "avg_trigram = pd.DataFrame(avg_trigram, columns=cv_trigram.get_feature_names())\n",
    "avg_trigram = avg_trigram.T\n",
    "avg_trigram = avg_trigram.rename(columns={0:'SCORE'}) \n",
    "avg_trigram['WORD'] = avg_trigram.index\n",
    "avg_trigram = avg_trigram.sort_values('SCORE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c124be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>WORD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>really good product</th>\n",
       "      <td>0.002986</td>\n",
       "      <td>really good product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like product much</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>like product much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love mamaearth product</th>\n",
       "      <td>0.001443</td>\n",
       "      <td>love mamaearth product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best face wash</th>\n",
       "      <td>0.001438</td>\n",
       "      <td>best face wash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mama earth product</th>\n",
       "      <td>0.001434</td>\n",
       "      <td>mama earth product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se bahut jain</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>se bahut jain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product ke main</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>product ke main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi achcha program</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>hi achcha program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se kah rahe</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>se kah rahe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mein result de</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>mein result de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149847 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SCORE                    WORD\n",
       "really good product     0.002986     really good product\n",
       "like product much       0.001465       like product much\n",
       "love mamaearth product  0.001443  love mamaearth product\n",
       "best face wash          0.001438          best face wash\n",
       "mama earth product      0.001434      mama earth product\n",
       "...                          ...                     ...\n",
       "se bahut jain           0.000003           se bahut jain\n",
       "product ke main         0.000003         product ke main\n",
       "hi achcha program       0.000003       hi achcha program\n",
       "se kah rahe             0.000003             se kah rahe\n",
       "mein result de          0.000003          mein result de\n",
       "\n",
       "[149847 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2700830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of avg_unigram and avg_trigram\n",
    "unigram_list = avg_unigram['WORD'].tolist()\n",
    "trigram_list = avg_trigram['WORD'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a0d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(listt):\n",
    "    return([i.split() for i in listt])\n",
    "\n",
    "trigram_split = convert(trigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "670776a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(columns=['TOPIC','SUB_TOPIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ff50555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in unigram_list:\n",
    "    counter=0\n",
    "    for k in trigram_split:\n",
    "        if counter<5 and (j==k[0] or j==k[1] or j==k[2]):\n",
    "            trigram_words = ' '.join(k)\n",
    "            test = pd.concat([test,pd.concat([pd.Series(j,name='TOPIC'),pd.Series(trigram_words,name='SUB_TOPIC')],axis=1)],axis=0)\n",
    "            counter=counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff188904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPIC</th>\n",
       "      <th>SUB_TOPIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product</td>\n",
       "      <td>really good product, like product much, love m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>really good product, product really good, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice</td>\n",
       "      <td>really nice product, nice product love, nice f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>like product much, really like product, like m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>love</td>\n",
       "      <td>love mamaearth product, good product love, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12038</th>\n",
       "      <td>usmein</td>\n",
       "      <td>usmein happy ki, kah rahe usmein, rahe usmein ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>karen</td>\n",
       "      <td>jain use karen, karen iske yah, use karen iske</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12040</th>\n",
       "      <td>pata</td>\n",
       "      <td>kiya mujhe pata, pata chala thank, mujhe pata ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12041</th>\n",
       "      <td>kah</td>\n",
       "      <td>acche se kah, kah rahe usmein, se kah rahe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>samajh</td>\n",
       "      <td>samajh mein nahin, bolu mujhe samajh, mujhe sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12043 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TOPIC                                          SUB_TOPIC\n",
       "0      product  really good product, like product much, love m...\n",
       "1         good  really good product, product really good, good...\n",
       "2         nice  really nice product, nice product love, nice f...\n",
       "3         like  like product much, really like product, like m...\n",
       "4         love  love mamaearth product, good product love, lov...\n",
       "...        ...                                                ...\n",
       "12038   usmein  usmein happy ki, kah rahe usmein, rahe usmein ...\n",
       "12039    karen     jain use karen, karen iske yah, use karen iske\n",
       "12040     pata  kiya mujhe pata, pata chala thank, mujhe pata ...\n",
       "12041      kah         acche se kah, kah rahe usmein, se kah rahe\n",
       "12042   samajh  samajh mein nahin, bolu mujhe samajh, mujhe sa...\n",
       "\n",
       "[12043 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new = test.groupby(['TOPIC'], as_index=False, sort=False).agg({'SUB_TOPIC':', '.join})\n",
    "test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a28353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want separate data file\n",
    "test_new.to_csv('04_Keyword_Extraction_using_TF-IDF.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab95ec",
   "metadata": {},
   "source": [
    "So, these are the codes for Keyword Extraction which we have performed in the previous data. We now have the keywords of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bdac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b9343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
